# nlp_100dailylogs
Will be logging my daily learning progress here.

#### Day 1 -> Apr 25th [224N Lecture-1](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=2&t=0s)

    Todo -> Lecture-1 Notes, Suggested
     readings, Softmax differentation and Assignment-1(in 1 week)

#### Day 2 -> Apr 26th [224N Lecture-1 Notes on WordVec 7/14](http://web.stanford.edu/class/cs224n/)

#### Day 3 -> Apr 28th [224N Lecture-1 Notes on WordVec 7-10/14](http://web.stanford.edu/class/cs224n/)

#### Day 4 -> Apr 29th
[224N Lecture-1 Notes completed](http://web.stanford.edu/class/cs224n/)

[224N Suggested material blog completed - Part 1&2 on Subsampling of frequent words and Negative sampling](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/)

[Heirarchical Softmax](https://www.youtube.com/watch?v=ioe1eeEWU0I)

#### Day 5 -> Apr 30th

Revised concepts from the [blog](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/).

#### Day 6 -> May 01st [224N Lecture-2](https://www.youtube.com/watch?v=kEMJRjEdNzM&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=2)

#### Day 7 -> May 03rd [224N Assignment-1](http://web.stanford.edu/class/cs224n/)

#### Day 8 -> May 06th [224N Lecture-2 Notes](http://web.stanford.edu/class/cs224n/)

#### Day 9 -> May 07th [224N Lecture-3 Video](https://www.youtube.com/watch?v=8CWyBNX6eDo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=3)

#### Day 10 -> May 09th [224N Original GloVe paper](http://nlp.stanford.edu/pubs/glove.pdf) and paper discussion on [Text-to-Text Transformer-T5 paper](https://arxiv.org/abs/1910.10683)

#### Day 11 -> May 11th [224N Paper - Improving Distributional Similarity with Lessons Learned from Word Embeddings](http://www.aclweb.org/anthology/Q15-1016)

#### Day 12 -> May 12th [Paper summary - LongFormer: The Long-Document Transformer](https://www.youtube.com/watch?v=_8KNb5iqblE)

#### Day 13 -> May 15th [224N Lecture-3 Notes 5/18](http://web.stanford.edu/class/cs224n/)

#### Day 14 -> May 17th [224N Lecture-3 Notes](http://web.stanford.edu/class/cs224n/)

#### Day 15 -> May 18th [224N Lecture-4 Video](https://www.youtube.com/watch?v=8CWyBNX6eDo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=4)

#### Day 16 -> May 19th [224N Lecture-4 Video & Lecture-3 Notes-Code on Word-Window classifier](https://www.youtube.com/watch?v=8CWyBNX6eDo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=4)

#### Day 17 -> May 21st [NLP Data Augmentation blog](https://amitness.com/2020/05/data-augmentation-for-nlp/) and [Stanford project notes on Data Augmentation](https://web.stanford.edu/class/cs224u/2019/materials/cs224-2019-data-augmentation.pdf)

#### Day 18 -> May 22nd [Slides for Data Augmentation](https://amitness.com/2020/05/data-augmentation-for-nlp/)

#### Day 19 -> May 23rd [Paper Discussion on Self-Attention & Convolution](https://arxiv.org/abs/1911.03584)

#### Day 20 -> May 25th [224 Assignment-2 Theoretical questions](http://web.stanford.edu/class/cs224n/)

#### Day 21 -> May 26th [224 Assignment-2 Practical questions](http://web.stanford.edu/class/cs224n/)

#### Day 22 -> May 29th [224 Lecture-5 Video](https://www.youtube.com/watch?v=nC9_RfjYwqA&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=5)

#### Day 23 -> May 30th [Paper reading & Discussion -> Experience Grounds Language](https://arxiv.org/abs/2004.10151)

#### Day 24 -> Jun 2nd [Lecture-5 Notes on Dependency Parsing](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes04-dependencyparsing.pdf) and [Lecture-5 remaining video](https://www.youtube.com/watch?v=nC9_RfjYwqA&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=5)

#### Day 25 -> Jun 3rd [Lecture-4 Suggested reading on Backprop & Computation graphs](http://cs231n.github.io/optimization-2/)

#### Day 26 -> Jun 4th [GPT-3 Paper Summary - Video](https://www.youtube.com/watch?v=SY5PvZrJhLE) and [Karpathy - Yes, you should understand Backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)

#### Day 27 -> Jun 6th [224 Lecture-6 Language Modeling](https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=6)

#### Day 28 -> Jun 7th [Blog on Zero-shot](https://amitness.com/2020/05/zero-shot-text-classification/) and [Pattern-Exploiting Training for NLP!](https://www.youtube.com/watch?v=01jRE9noSWw) and Revisited [Word-Translation without Parallel Data](https://arxiv.org/abs/1710.04087)

#### Day 29 -> Jun 8th Paper reading -[A Fast and Accurate Dependency Parser using Neural Networks](https://www.emnlp2014.org/papers/pdf/EMNLP2014082.pdf) and [224 Assignment-3 Theory on Adam, Dropout](http://web.stanford.edu/class/cs224n/)

#### Day 30 -> Jun 9th Blog - [PEGASUS: A State-of-the-Art Model for Abstractive Text Summarization](https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html)

#### Day 31 -> Jun 12th Blog - [Paper Reading -> TransCoder: Unsupervised Translation of Programming Languages](https://arxiv.org/abs/2006.03511) and [video](https://www.youtube.com/watch?v=xTzFJIknh7E). [Paper Reading -> Phrase Based & Neural Unsupervised Machine Translation](https://arxiv.org/abs/1804.07755)

#### Day 32 -> Jun 16th Assignment -> Dependency parsing assignment code. Assgnmt-3 224n

#### Day 33 -> Jun 19th -> [Paper Reading -> When BERT plays lottery, All Tickets are Winning](https://arxiv.org/abs/2005.00561) and [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://arxiv.org/abs/1803.03635)

## Sorry for the large gap

#### Day 34 -> Jul 4th -> [Paper Reading -> Learning to Learn Words from Visual Scenes](https://arxiv.org/abs/1911.11237)

#### Day 35 -> Jul 5th -> [CS224-N Lecture-6 Notes](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf)

#### Day 36 -> Jul 9th -> [CS224-N Lecture-7 Video](https://www.youtube.com/watch?v=QEw0qEa0E50)

#### Day 37 -> Jul 10th -> [Paper reading -> Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data](https://www.aclweb.org/anthology/2020.acl-main.463.pdf)